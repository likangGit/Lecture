{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深入了解MXnet中的Gluon\n",
    "\n",
    "## 1. Gluon简介\n",
    "> Gluon package is a high-level interface for MXNet designed easy to use while keeping most flexibility of low-level API. Gluon supports both imperative and symbolic programming, making it easy to train complex models imperatively in Python and deploy with symbolic graph in C++.  \n",
    "  \n",
    "### 1.1 定位\n",
    "\n",
    "- **科研**  \n",
    ">命令式编程的方式，随时能够运行结果，跟写python程序的方式一致，不用像tensorflow一样要先定义graph，启动session运行；由此在构建网络过程中,debug效率更高，出了问题就能够直接定位；\n",
    "- **产品**\n",
    ">科研和工业界可以都用同一个框架开发，避免的代码的重写，减少劳动效率，避免出现问题\n",
    "\n",
    "### 1.2 优势\n",
    "- API简单易用, 从 pytorch keras中积累的经验可以直接应用在gluon中 \n",
    "- MXnet速度快，省显存，并行效率高，分布式简单\n",
    "- 支持动态图和静态图的转换  \n",
    "\n",
    "<img src=\"./DLFrameWork/framework.jpg\" width = \"600\" align=center /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gluon API\n",
    "这一部分是从Mxnet文档中copy,详细内容可以查询文档[Gluon Package](https://mxnet.incubator.apache.org/api/python/gluon/gluon.html)\n",
    "### 2.1基础模块\n",
    "* Parameter\n",
    "\n",
    "|||\n",
    "|:---|:---|\n",
    "|Parameter| \tA Container holding parameters (weights) of Blocks.|\n",
    "|Constant| \tA constant parameter for holding immutable tensors.|\n",
    "|ParameterDict| \tA dictionary managing a set of parameters.|\n",
    "\n",
    "* Containers  \n",
    "\n",
    "|||\n",
    "|:----|:----|\n",
    "|Block \t             |   Base class for all neural network layers and models.|\n",
    "|HybridBlock \t     |   HybridBlock supports forwarding with both Symbol and NDArray.|\n",
    "|SymbolBlock \t     |   Construct block from symbol.|\n",
    "|nn.Sequential \t     |   Stacks Blocks sequentially.|\n",
    "|nn.HybridSequential |\tStacks HybridBlocks sequentially.|        \n",
    "* Trainer\n",
    "* Utilities\n",
    "    \n",
    "    \n",
    "### 2.2 深度学习模块\n",
    "- Neural Network Layers\n",
    "- Recurrent Neural Network \n",
    "- Loss \n",
    "- Data \n",
    "- Model Zoo\n",
    "- Contrib\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gluon使用\n",
    "以下通过构建深度学习应用的顺序来介绍如何使用Gluon, 这里假设大家已经掌握了使用某一种框架构建模型的基本技能, Mxnet和Gluon基础参照上一次课程的Mxnet部分.  \n",
    "下面以构建性别分析模型为例, 逐个过程介绍.\n",
    "### 3.1 数据准备\n",
    "在这个例子中我们使用[the IMDB-WIKI dataset](https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/)作为训练数据, 官方提供了此数据集的人脸区域crop数据, 其标注格式保存为`.mat`类型, 可以通过`scipy`中的工具进行读取,转化为我们需要的形式. \n",
    "\n",
    "<img src=\"./mxnetTL/imdb-wiki-teaser.png\" width = \"600\" align=center />   \n",
    "需要注意的是, 官方提供的crop数据中有很多误检的图片, 可以通过标注中的置信度过滤这些图片."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "from datetime import datetime\n",
    "\n",
    "def get_meta(mat_path, db):\n",
    "    meta = loadmat(mat_path)\n",
    "    full_path = meta[db][0, 0][\"full_path\"][0]\n",
    "    dob = meta[db][0, 0][\"dob\"][0]  # Matlab serial date number\n",
    "    gender = meta[db][0, 0][\"gender\"][0]\n",
    "    photo_taken = meta[db][0, 0][\"photo_taken\"][0]  # year\n",
    "    face_score = meta[db][0, 0][\"face_score\"][0]\n",
    "    second_face_score = meta[db][0, 0][\"second_face_score\"][0]\n",
    "    age = [calc_age(photo_taken[i], dob[i]) for i in range(len(dob))]\n",
    "\n",
    "    return full_path, dob, gender, photo_taken, face_score, second_face_score, age\n",
    "\n",
    "def calc_age(taken, dob):\n",
    "    birth = datetime.fromordinal(max(int(dob) - 366, 1))\n",
    "\n",
    "    # assume the photo was taken in the middle of the year\n",
    "    if birth.month < 7:\n",
    "        return taken - birth.year\n",
    "    else:\n",
    "        return taken - birth.year - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是通过scipy中的工具来读取官方标注信息,通过分数过滤掉不符合标准的图像.然后按照9:1的比例划分训练集和测试集."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62328/62328 [00:00<00:00, 251782.58it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "db = \"wiki\"\n",
    "min_score = 1.0\n",
    "train_path = \"./mxnetTL/%s_train.lst\" % db\n",
    "val_path = \"./mxnetTL/%s_val.lst\" % db\n",
    "root_path = \"/home/bmi/data/{}_crop/\".format(db)\n",
    "mat_path = root_path + \"{}.mat\".format(db)\n",
    "full_path, dob, gender, photo_taken, face_score, second_face_score, age = get_meta(mat_path, db)\n",
    "image_list = []\n",
    "\n",
    "for i in tqdm(range(len(face_score))):\n",
    "    if face_score[i] < min_score:\n",
    "        continue\n",
    "    if (~np.isnan(second_face_score[i])) and second_face_score[i] > 0.0:\n",
    "        continue\n",
    "    if ~(0 <= age[i] <= 100):\n",
    "        continue\n",
    "    if np.isnan(gender[i]):\n",
    "        continue\n",
    "    image_list.append(\"%s,%d,%d\\n\" % (str(full_path[i][0]),int(gender[i]),age[i]))\n",
    "\n",
    "random.seed(100)\n",
    "random.shuffle(image_list)\n",
    "N = len(image_list)\n",
    "sep = int(N * 0.9)\n",
    "with open(train_path, 'w') as f:\n",
    "    f.write(\"image_path,gender,age\\n\")\n",
    "    for annotation in image_list[:sep]:\n",
    "        f.write(annotation)\n",
    "with open(val_path, 'w') as f:\n",
    "    f.write(\"image_path,gender,age\\n\")\n",
    "    for annotation in image_list[sep:]:\n",
    "        f.write(annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 数据导入\n",
    "在任何一个框架下进行训练,数据的导入都是最基本的工作.  \n",
    "常见的几种框架采用了不同方式来完成这个部分:  \n",
    "- caffe: lmdb\n",
    "- tensorflow: 过去采用tfrecord;在最近版本中引入了新的Data模块\n",
    "- mxnet: 由train.lst生成train.rec;Gluon中的dataAPI  \n",
    "\n",
    "这里没有提及从opencv或其他图像库读入图片,然后做预处理再送到网络进行训练的方法,最好的方式是利用框架提供的模块来加速数据处理,避免准备数据的部分成为训练速度瓶颈.  \n",
    "\n",
    "#### Gluon data API的使用方法\n",
    "文档中对dataset类的描述:\n",
    "```python\n",
    "    \"\"\"Abstract dataset class. All datasets should have this interface.\n",
    "\n",
    "    Subclasses need to override `__getitem__`, which returns the i-th\n",
    "    element, and `__len__`, which returns the total number elements.\n",
    "\n",
    "    .. note:: An mxnet or numpy array can be directly used as a dataset.\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "- 简单说明  \n",
    "下面的代码块是根据gluon中API实现的多任务网络数据集类, 可作为`DataLoader`的参数进行数据读取.\n",
    "使用时需要根据文档中的说明生成lst文件, 目前仅支持每个image具有同样数目label的情况\n",
    "\n",
    "- 注意事项  \n",
    "在数据集未做预处理时需要自行定义transform来进行图像处理,\n",
    "如果不能统一图像尺寸, 在读取批次时会报错  \n",
    "\n",
    "```python\n",
    " \"\"\"A dataset for loading image files stored in a image-label list file like::\n",
    "\n",
    "          image_path          gender       age\n",
    "          root/01/0001.jpg      0          45\n",
    "          root/02/xxxa.jpg      1          10\n",
    "          root/03/yyyb.jpg      0          25\n",
    "          root/04/123.jpg       1          34\n",
    "          root/05/023.jpg       1          22\n",
    "          root/06/wwww.jpg      0          21\n",
    "\n",
    "      Parameters\n",
    "      ----------\n",
    "      root : str\n",
    "          Path to root directory.\n",
    "      flag : {0, 1}, default 1\n",
    "          If 0, always convert loaded images to greyscale (1 channel).\n",
    "          If 1, always convert loaded images to colored (3 channels).\n",
    "      transform : callable, default None\n",
    "          A function that takes data and label and transforms them:\n",
    "      ::\n",
    "\n",
    "          transform = lambda data, label: (data.astype(np.float32)/255, label)\n",
    "\n",
    "      Attributes\n",
    "      ----------\n",
    "      synsets : dict\n",
    "          Dict of labels. as an example:\n",
    "          synsets = {\"label1\": [\"male\", \"female\"],\n",
    "                     \"label2\": [age for age in range(100)],\n",
    "                     ...}\n",
    "\n",
    "          `synsets[\"label1\"]` is list of gender classes,\n",
    "          `synsets[\"label2\"]` is list of age classes,\n",
    "          `synsets[\"label\"][i]` is the name for the integer label `i`.\n",
    "      items : list of tuples\n",
    "          List of all images in (filename, labels) pairs. that\n",
    "      labels contains two element in this example, `[0, 25]`\n",
    "      \"\"\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from mxnet import image\n",
    "from mxnet.gluon.data import Dataset, DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class MultiTaskDataset(Dataset):\n",
    "    def __init__(self, root, image_lst_path, flag=1, transform=None):\n",
    "        self._root = os.path.expanduser(root)\n",
    "        self._image_lst = os.path.expanduser(image_lst_path)\n",
    "        self._flag = flag\n",
    "        self._transform = transform\n",
    "        self._exts = ['.jpg', '.jpeg', '.png']\n",
    "        self._list_images()\n",
    "\n",
    "    def _list_images(self):\n",
    "        self.tasks = []\n",
    "        self.items = []\n",
    "\n",
    "        with open(self._image_lst, \"r\") as f:\n",
    "            lst_title = f.readline().strip('\\n').split(',')\n",
    "            self.tasks = lst_title[1:]\n",
    "\n",
    "            for line in f.readlines():\n",
    "                filename_and_labels = line.strip('\\n').split(',')\n",
    "                _item = [os.path.join(self._root, filename_and_labels[0]), filename_and_labels[1:]]\n",
    "                self.items.append(_item)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = image.imread(os.path.join(self.items[idx][0]), self._flag)\n",
    "        _labels = self.items[idx][1]\n",
    "\n",
    "        if self._transform is not None:\n",
    "            return self._transform(img, _labels)\n",
    "        return img, _labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据准备工作到这步基本完成, 然后定义预处理图像的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import nd\n",
    "from mxnetTL.utils import ten_crop\n",
    "\n",
    "def transform_train(data, labels):\n",
    "    im = data.astype('float32') / 255\n",
    "    auglist = image.CreateAugmenter(data_shape=(3, 224, 224), resize=256,\n",
    "                                    rand_crop=False, rand_mirror=True,\n",
    "                                    mean=np.array([0.485, 0.456, 0.406]),\n",
    "                                    std=np.array([0.229, 0.224, 0.225]))\n",
    "    for aug in auglist:\n",
    "        im = aug(im)\n",
    "    im = nd.transpose(im, (2, 0, 1))\n",
    "    return im, nd.array(labels).asnumpy()\n",
    "\n",
    "def transform_val(data, labels):\n",
    "    im = data.astype('float32') / 255\n",
    "    im = image.resize_short(im, 140)\n",
    "    im, _ = image.center_crop(im, (112, 112))\n",
    "    im = nd.transpose(im, (2, 0, 1))\n",
    "    return im, nd.array(labels).asnumpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建数据的生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet import gluon\n",
    "\n",
    "data_root = \"/home/bmi/data/wiki_crop\"\n",
    "batch_size = 32\n",
    "num_workers = 2\n",
    "\n",
    "train_set = MultiTaskDataset(root=os.path.join(data_root), image_lst_path=\"./mxnetTL/wiki_train.lst\",\n",
    "                                 transform=transform_train)\n",
    "train_data = gluon.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers,\n",
    "                                       last_batch='discard')\n",
    "\n",
    "val_set = MultiTaskDataset(root=os.path.join(data_root), image_lst_path=\"./mxnetTL/wiki_val.lst\",\n",
    "                           transform=transform_val)\n",
    "val_data = gluon.data.DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试下读取数据的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "\n",
      "[[[ 1.16079998e+00  1.17870653e+00  1.63065469e+00 ...  9.72791016e-01\n",
      "    8.37057710e-01  8.66802752e-01]\n",
      "  [ 1.27612579e+00  1.21978688e+00  9.56013203e-01 ...  9.02998924e-01\n",
      "    7.47758985e-01  8.39927852e-01]\n",
      "  [ 1.20971787e+00  1.20115232e+00  1.15227234e+00 ...  8.46235752e-01\n",
      "    8.43385398e-01  8.62377405e-01]\n",
      "  ...\n",
      "  [-6.54119730e-01 -6.50769114e-01 -5.82242131e-01 ... -1.53073478e+00\n",
      "   -1.08005512e+00 -8.35051060e-01]\n",
      "  [-6.19605243e-01 -6.09470367e-01 -6.12057865e-01 ... -1.53429043e+00\n",
      "   -1.11069977e+00 -7.65824020e-01]\n",
      "  [-6.04440033e-01 -5.94417572e-01 -6.28620744e-01 ... -1.45021200e+00\n",
      "   -1.23045743e+00 -8.71806562e-01]]\n",
      "\n",
      " [[ 1.01274671e-03  2.05713194e-02  4.98286426e-01 ... -8.92438516e-02\n",
      "   -3.09154779e-01 -3.08188468e-01]\n",
      "  [ 1.27349183e-01  6.54564053e-02 -2.43399158e-01 ... -1.57128617e-01\n",
      "   -4.01640564e-01 -3.64046127e-01]\n",
      "  [ 1.23969674e-01  1.08714879e-01 -5.15646674e-03 ... -1.96133867e-01\n",
      "   -2.00141087e-01 -1.81430817e-01]\n",
      "  ...\n",
      "  [ 3.83875184e-02  4.20629159e-02  1.15344964e-01 ... -8.38083208e-01\n",
      "   -3.62311065e-01 -1.11992598e-01]\n",
      "  [ 7.33379275e-02  8.51303339e-02  9.85836834e-02 ... -8.26132178e-01\n",
      "   -3.92690301e-01 -4.50547226e-02]\n",
      "  [ 8.77871290e-02  1.03796832e-01  1.26909465e-01 ... -7.42367983e-01\n",
      "   -4.70777154e-01 -9.95702222e-02]]\n",
      "\n",
      " [[-7.58679867e-01 -7.74050355e-01 -6.38719797e-01 ... -1.00460911e+00\n",
      "   -1.22001433e+00 -1.22008729e+00]\n",
      "  [-6.46153450e-01 -7.38512874e-01 -1.34745443e+00 ... -1.06526697e+00\n",
      "   -1.30904126e+00 -1.25923383e+00]\n",
      "  [-7.71048009e-01 -7.75415599e-01 -7.82918811e-01 ... -1.07150292e+00\n",
      "   -1.07549620e+00 -1.05671966e+00]\n",
      "  ...\n",
      "  [-3.58324572e-02 -3.22698243e-02  3.97170931e-02 ... -1.03043377e+00\n",
      "   -5.56614041e-01 -3.07202876e-01]\n",
      "  [-1.05725392e-03  1.07529433e-02  2.41674315e-02 ... -1.01853967e+00\n",
      "   -5.87215304e-01 -2.39491999e-01]\n",
      "  [ 1.36706568e-02  2.82981675e-02  3.77386138e-02 ... -9.34451401e-01\n",
      "   -6.79673135e-01 -3.11661184e-01]]]\n",
      "<NDArray 3x224x224 @cpu_shared(0)>\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_data):\n",
    "    if i > 0:\n",
    "        break\n",
    "    print(batch[0].shape)\n",
    "    print(batch[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 单机多卡训练\n",
    "使用mxnet框架在进行训练时,可以很容易实现利用多GPU加速训练. 这里以单机多卡为例, 先定义一些训练所需参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "db = \"wiki\"\n",
    "lr = 0.01\n",
    "batch_size = 128\n",
    "\n",
    "momentum = 0.9\n",
    "wd = 1e-4\n",
    "\n",
    "lr_factor = 0.75\n",
    "lr_steps = [5,7,9,np.inf]\n",
    "\n",
    "\n",
    "num_gpus = 2\n",
    "num_workers = 2\n",
    "ctx = [mx.gpu(i) for i in range(num_gpus)] if num_gpus > 0 else [mx.cpu()]\n",
    "batch_size = batch_size * max(num_gpus, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用迁移学习\n",
    "Gluon中提供了一系列经典网络结构在image_net上训练好的模型, 在这个基础上实现自己的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon.model_zoo import vision as models\n",
    "\n",
    "pretrained_net = models.resnet18_v2(pretrained=True)\n",
    "\n",
    "finetune_net = models.resnet18_v2(classes=2)\n",
    "finetune_net.features = pretrained_net.features\n",
    "finetune_net.output.initialize(mx.init.Xavier())\n",
    "finetune_net.collect_params().reset_ctx(ctx)\n",
    "finetune_net.hybridize()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 通常的网络实现方法\n",
    "利用`nn.block`实现两个类, 第一个是用resnet18接多输出的网络,做多任务学习; 第二个是inception中的基本单元, 如下图:\n",
    "<img src=\"http://zh.gluon.ai/_images/inception.svg\" width = \"400\" align=center />   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon import nn\n",
    "from mxnet import nd\n",
    "\n",
    "\n",
    "class MultiTaskAG(nn.HybridBlock):\n",
    "    def __init__(self, branch1_classes, branch2_classes, **kwargs):\n",
    "        super(MultiTaskAG, self).__init__(**kwargs)\n",
    "        self.features = nn.HybridSequential()\n",
    "        self.output1 = nn.HybridSequential()\n",
    "        self.output2 = nn.HybridSequential()\n",
    "        with self.name_scope():\n",
    "            self.features.add(\n",
    "                nn.Conv2D(32, kernel_size=3, activation='relu'),\n",
    "                nn.Conv2D(64, kernel_size=5, activation='relu'),\n",
    "                nn.Conv2D(32, kernel_size=3, activation='relu'),\n",
    "                nn.Flatten()\n",
    "            )\n",
    "        with self.name_scope():\n",
    "            self.output1.add(nn.Dense(branch1_classes))\n",
    "            self.output2.add(nn.Dense(branch2_classes))\n",
    "\n",
    "    def hybrid_forward(self, F, x, *args, **kwargs):\n",
    "        x = self.features(x)\n",
    "        result1 = self.output1(x)\n",
    "        result2 = self.output2(x)\n",
    "        return result1, result2\n",
    "    \n",
    "\n",
    "class Inception(nn.HybridBlock):\n",
    "    def __init__(self, n1_1, n2_1, n2_3, n3_1, n3_5, n4_1, **kwargs):\n",
    "        super(Inception, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            # path 1\n",
    "            self.p1_conv_1 = nn.Conv2D(n1_1, kernel_size=1,\n",
    "                                       activation='relu')\n",
    "            # path 2\n",
    "            self.p2_conv_1 = nn.Conv2D(n2_1, kernel_size=1,\n",
    "                                       activation='relu')\n",
    "            self.p2_conv_3 = nn.Conv2D(n2_3, kernel_size=3, padding=1,\n",
    "                                       activation='relu')\n",
    "            # path 3\n",
    "            self.p3_conv_1 = nn.Conv2D(n3_1, kernel_size=1,\n",
    "                                       activation='relu')\n",
    "            self.p3_conv_5 = nn.Conv2D(n3_5, kernel_size=5, padding=2,\n",
    "                                       activation='relu')\n",
    "            # path 4\n",
    "            self.p4_pool_3 = nn.MaxPool2D(pool_size=3, padding=1,\n",
    "                                          strides=1)\n",
    "            self.p4_conv_1 = nn.Conv2D(n4_1, kernel_size=1,\n",
    "                                       activation='relu')\n",
    "\n",
    "    def hybrid_forward(self, F, x, *args, **kwargs):\n",
    "        p1 = self.p1_conv_1(x)\n",
    "        p2 = self.p2_conv_3(self.p2_conv_1(x))\n",
    "        p3 = self.p3_conv_5(self.p3_conv_1(x))\n",
    "        p4 = self.p4_conv_1(self.p4_pool_3(x))\n",
    "        return F.concat(p1, p2, p3, p4, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用可视化工具展示网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: plot Pages: 1 -->\n",
       "<svg width=\"438pt\" height=\"536pt\"\n",
       " viewBox=\"0.00 0.00 438.00 536.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 532)\">\n",
       "<title>plot</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-532 434,-532 434,4 -4,4\"/>\n",
       "<!-- data -->\n",
       "<g id=\"node1\" class=\"node\"><title>data</title>\n",
       "<ellipse fill=\"#8dd3c7\" stroke=\"black\" cx=\"215\" cy=\"-29\" rx=\"47\" ry=\"29\"/>\n",
       "<text text-anchor=\"middle\" x=\"215\" y=\"-25.3\" font-family=\"Times,serif\" font-size=\"14.00\">data</text>\n",
       "</g>\n",
       "<!-- inception1_conv0_fwd -->\n",
       "<g id=\"node2\" class=\"node\"><title>inception1_conv0_fwd</title>\n",
       "<polygon fill=\"#fb8072\" stroke=\"black\" points=\"94,-152 -7.10543e-15,-152 -7.10543e-15,-94 94,-94 94,-152\"/>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\">Convolution</text>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\">1x1/1x1, 64</text>\n",
       "</g>\n",
       "<!-- inception1_conv0_fwd&#45;&gt;data -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>inception1_conv0_fwd&#45;&gt;data</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M103.134,-91.2598C128.78,-77.2157 158.334,-61.0315 180.622,-48.8261\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"94.2444,-96.128 100.854,-87.3779 98.6299,-93.7264 103.015,-91.3248 103.015,-91.3248 103.015,-91.3248 98.6299,-93.7264 105.177,-95.2718 94.2444,-96.128 94.2444,-96.128\"/>\n",
       "</g>\n",
       "<!-- inception1_conv0_relu_fwd -->\n",
       "<g id=\"node3\" class=\"node\"><title>inception1_conv0_relu_fwd</title>\n",
       "<polygon fill=\"#ffffb3\" stroke=\"black\" points=\"94,-340 -7.10543e-15,-340 -7.10543e-15,-282 94,-282 94,-340\"/>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\">Activation</text>\n",
       "<text text-anchor=\"middle\" x=\"47\" y=\"-299.8\" font-family=\"Times,serif\" font-size=\"14.00\">relu</text>\n",
       "</g>\n",
       "<!-- inception1_conv0_relu_fwd&#45;&gt;inception1_conv0_fwd -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>inception1_conv0_relu_fwd&#45;&gt;inception1_conv0_fwd</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47,-271.746C47,-236.206 47,-184.104 47,-152.21\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"47,-281.751 42.5001,-271.751 47,-276.751 47.0001,-271.751 47.0001,-271.751 47.0001,-271.751 47,-276.751 51.5001,-271.751 47,-281.751 47,-281.751\"/>\n",
       "</g>\n",
       "<!-- inception1_conv1_fwd -->\n",
       "<g id=\"node4\" class=\"node\"><title>inception1_conv1_fwd</title>\n",
       "<polygon fill=\"#fb8072\" stroke=\"black\" points=\"206,-152 112,-152 112,-94 206,-94 206,-152\"/>\n",
       "<text text-anchor=\"middle\" x=\"159\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\">Convolution</text>\n",
       "<text text-anchor=\"middle\" x=\"159\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\">1x1/1x1, 96</text>\n",
       "</g>\n",
       "<!-- inception1_conv1_fwd&#45;&gt;data -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>inception1_conv1_fwd&#45;&gt;data</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M181.377,-85.2374C187.257,-75.5783 193.481,-65.3525 198.955,-56.3597\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"176.106,-93.8971 177.462,-83.0153 178.706,-89.6261 181.306,-85.3551 181.306,-85.3551 181.306,-85.3551 178.706,-89.6261 185.15,-87.6949 176.106,-93.8971 176.106,-93.8971\"/>\n",
       "</g>\n",
       "<!-- inception1_conv1_relu_fwd -->\n",
       "<g id=\"node5\" class=\"node\"><title>inception1_conv1_relu_fwd</title>\n",
       "<polygon fill=\"#ffffb3\" stroke=\"black\" points=\"206,-246 112,-246 112,-188 206,-188 206,-246\"/>\n",
       "<text text-anchor=\"middle\" x=\"159\" y=\"-220.8\" font-family=\"Times,serif\" font-size=\"14.00\">Activation</text>\n",
       "<text text-anchor=\"middle\" x=\"159\" y=\"-205.8\" font-family=\"Times,serif\" font-size=\"14.00\">relu</text>\n",
       "</g>\n",
       "<!-- inception1_conv1_relu_fwd&#45;&gt;inception1_conv1_fwd -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>inception1_conv1_relu_fwd&#45;&gt;inception1_conv1_fwd</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M159,-177.744C159,-169.204 159,-160.298 159,-152.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"159,-187.897 154.5,-177.897 159,-182.897 159,-177.897 159,-177.897 159,-177.897 159,-182.897 163.5,-177.897 159,-187.897 159,-187.897\"/>\n",
       "</g>\n",
       "<!-- inception1_conv2_fwd -->\n",
       "<g id=\"node6\" class=\"node\"><title>inception1_conv2_fwd</title>\n",
       "<polygon fill=\"#fb8072\" stroke=\"black\" points=\"206,-340 112,-340 112,-282 206,-282 206,-340\"/>\n",
       "<text text-anchor=\"middle\" x=\"159\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\">Convolution</text>\n",
       "<text text-anchor=\"middle\" x=\"159\" y=\"-299.8\" font-family=\"Times,serif\" font-size=\"14.00\">3x3/1x1, 128</text>\n",
       "</g>\n",
       "<!-- inception1_conv2_fwd&#45;&gt;inception1_conv1_relu_fwd -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>inception1_conv2_fwd&#45;&gt;inception1_conv1_relu_fwd</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M159,-271.744C159,-263.204 159,-254.298 159,-246.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"159,-281.897 154.5,-271.897 159,-276.897 159,-271.897 159,-271.897 159,-271.897 159,-276.897 163.5,-271.897 159,-281.897 159,-281.897\"/>\n",
       "</g>\n",
       "<!-- inception1_conv2_relu_fwd -->\n",
       "<g id=\"node7\" class=\"node\"><title>inception1_conv2_relu_fwd</title>\n",
       "<polygon fill=\"#ffffb3\" stroke=\"black\" points=\"206,-434 112,-434 112,-376 206,-376 206,-434\"/>\n",
       "<text text-anchor=\"middle\" x=\"159\" y=\"-408.8\" font-family=\"Times,serif\" font-size=\"14.00\">Activation</text>\n",
       "<text text-anchor=\"middle\" x=\"159\" y=\"-393.8\" font-family=\"Times,serif\" font-size=\"14.00\">relu</text>\n",
       "</g>\n",
       "<!-- inception1_conv2_relu_fwd&#45;&gt;inception1_conv2_fwd -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>inception1_conv2_relu_fwd&#45;&gt;inception1_conv2_fwd</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M159,-365.744C159,-357.204 159,-348.298 159,-340.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"159,-375.897 154.5,-365.897 159,-370.897 159,-365.897 159,-365.897 159,-365.897 159,-370.897 163.5,-365.897 159,-375.897 159,-375.897\"/>\n",
       "</g>\n",
       "<!-- inception1_conv3_fwd -->\n",
       "<g id=\"node8\" class=\"node\"><title>inception1_conv3_fwd</title>\n",
       "<polygon fill=\"#fb8072\" stroke=\"black\" points=\"318,-152 224,-152 224,-94 318,-94 318,-152\"/>\n",
       "<text text-anchor=\"middle\" x=\"271\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\">Convolution</text>\n",
       "<text text-anchor=\"middle\" x=\"271\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\">1x1/1x1, 16</text>\n",
       "</g>\n",
       "<!-- inception1_conv3_fwd&#45;&gt;data -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>inception1_conv3_fwd&#45;&gt;data</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M248.623,-85.2374C242.743,-75.5783 236.519,-65.3525 231.045,-56.3597\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"253.894,-93.8971 244.85,-87.6949 251.294,-89.6261 248.694,-85.3551 248.694,-85.3551 248.694,-85.3551 251.294,-89.6261 252.538,-83.0153 253.894,-93.8971 253.894,-93.8971\"/>\n",
       "</g>\n",
       "<!-- inception1_conv3_relu_fwd -->\n",
       "<g id=\"node9\" class=\"node\"><title>inception1_conv3_relu_fwd</title>\n",
       "<polygon fill=\"#ffffb3\" stroke=\"black\" points=\"318,-246 224,-246 224,-188 318,-188 318,-246\"/>\n",
       "<text text-anchor=\"middle\" x=\"271\" y=\"-220.8\" font-family=\"Times,serif\" font-size=\"14.00\">Activation</text>\n",
       "<text text-anchor=\"middle\" x=\"271\" y=\"-205.8\" font-family=\"Times,serif\" font-size=\"14.00\">relu</text>\n",
       "</g>\n",
       "<!-- inception1_conv3_relu_fwd&#45;&gt;inception1_conv3_fwd -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>inception1_conv3_relu_fwd&#45;&gt;inception1_conv3_fwd</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M271,-177.744C271,-169.204 271,-160.298 271,-152.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"271,-187.897 266.5,-177.897 271,-182.897 271,-177.897 271,-177.897 271,-177.897 271,-182.897 275.5,-177.897 271,-187.897 271,-187.897\"/>\n",
       "</g>\n",
       "<!-- inception1_conv4_fwd -->\n",
       "<g id=\"node10\" class=\"node\"><title>inception1_conv4_fwd</title>\n",
       "<polygon fill=\"#fb8072\" stroke=\"black\" points=\"318,-340 224,-340 224,-282 318,-282 318,-340\"/>\n",
       "<text text-anchor=\"middle\" x=\"271\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\">Convolution</text>\n",
       "<text text-anchor=\"middle\" x=\"271\" y=\"-299.8\" font-family=\"Times,serif\" font-size=\"14.00\">5x5/1x1, 32</text>\n",
       "</g>\n",
       "<!-- inception1_conv4_fwd&#45;&gt;inception1_conv3_relu_fwd -->\n",
       "<g id=\"edge9\" class=\"edge\"><title>inception1_conv4_fwd&#45;&gt;inception1_conv3_relu_fwd</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M271,-271.744C271,-263.204 271,-254.298 271,-246.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"271,-281.897 266.5,-271.897 271,-276.897 271,-271.897 271,-271.897 271,-271.897 271,-276.897 275.5,-271.897 271,-281.897 271,-281.897\"/>\n",
       "</g>\n",
       "<!-- inception1_conv4_relu_fwd -->\n",
       "<g id=\"node11\" class=\"node\"><title>inception1_conv4_relu_fwd</title>\n",
       "<polygon fill=\"#ffffb3\" stroke=\"black\" points=\"318,-434 224,-434 224,-376 318,-376 318,-434\"/>\n",
       "<text text-anchor=\"middle\" x=\"271\" y=\"-408.8\" font-family=\"Times,serif\" font-size=\"14.00\">Activation</text>\n",
       "<text text-anchor=\"middle\" x=\"271\" y=\"-393.8\" font-family=\"Times,serif\" font-size=\"14.00\">relu</text>\n",
       "</g>\n",
       "<!-- inception1_conv4_relu_fwd&#45;&gt;inception1_conv4_fwd -->\n",
       "<g id=\"edge10\" class=\"edge\"><title>inception1_conv4_relu_fwd&#45;&gt;inception1_conv4_fwd</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M271,-365.744C271,-357.204 271,-348.298 271,-340.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"271,-375.897 266.5,-365.897 271,-370.897 271,-365.897 271,-365.897 271,-365.897 271,-370.897 275.5,-365.897 271,-375.897 271,-375.897\"/>\n",
       "</g>\n",
       "<!-- inception1_pool0_fwd -->\n",
       "<g id=\"node12\" class=\"node\"><title>inception1_pool0_fwd</title>\n",
       "<polygon fill=\"#80b1d3\" stroke=\"black\" points=\"430,-246 336,-246 336,-188 430,-188 430,-246\"/>\n",
       "<text text-anchor=\"middle\" x=\"383\" y=\"-220.8\" font-family=\"Times,serif\" font-size=\"14.00\">Pooling</text>\n",
       "<text text-anchor=\"middle\" x=\"383\" y=\"-205.8\" font-family=\"Times,serif\" font-size=\"14.00\">max, 3x3/1x1</text>\n",
       "</g>\n",
       "<!-- inception1_pool0_fwd&#45;&gt;data -->\n",
       "<g id=\"edge11\" class=\"edge\"><title>inception1_pool0_fwd&#45;&gt;data</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M372.511,-178.438C363.729,-152.352 349.04,-118.09 327,-94 307.045,-72.1894 277.892,-55.8553 254.331,-45.1489\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"375.591,-187.997 368.241,-179.858 374.058,-183.237 372.524,-178.478 372.524,-178.478 372.524,-178.478 374.058,-183.237 376.807,-177.098 375.591,-187.997 375.591,-187.997\"/>\n",
       "</g>\n",
       "<!-- inception1_conv5_fwd -->\n",
       "<g id=\"node13\" class=\"node\"><title>inception1_conv5_fwd</title>\n",
       "<polygon fill=\"#fb8072\" stroke=\"black\" points=\"430,-340 336,-340 336,-282 430,-282 430,-340\"/>\n",
       "<text text-anchor=\"middle\" x=\"383\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\">Convolution</text>\n",
       "<text text-anchor=\"middle\" x=\"383\" y=\"-299.8\" font-family=\"Times,serif\" font-size=\"14.00\">1x1/1x1, 32</text>\n",
       "</g>\n",
       "<!-- inception1_conv5_fwd&#45;&gt;inception1_pool0_fwd -->\n",
       "<g id=\"edge12\" class=\"edge\"><title>inception1_conv5_fwd&#45;&gt;inception1_pool0_fwd</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M383,-271.744C383,-263.204 383,-254.298 383,-246.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"383,-281.897 378.5,-271.897 383,-276.897 383,-271.897 383,-271.897 383,-271.897 383,-276.897 387.5,-271.897 383,-281.897 383,-281.897\"/>\n",
       "</g>\n",
       "<!-- inception1_conv5_relu_fwd -->\n",
       "<g id=\"node14\" class=\"node\"><title>inception1_conv5_relu_fwd</title>\n",
       "<polygon fill=\"#ffffb3\" stroke=\"black\" points=\"430,-434 336,-434 336,-376 430,-376 430,-434\"/>\n",
       "<text text-anchor=\"middle\" x=\"383\" y=\"-408.8\" font-family=\"Times,serif\" font-size=\"14.00\">Activation</text>\n",
       "<text text-anchor=\"middle\" x=\"383\" y=\"-393.8\" font-family=\"Times,serif\" font-size=\"14.00\">relu</text>\n",
       "</g>\n",
       "<!-- inception1_conv5_relu_fwd&#45;&gt;inception1_conv5_fwd -->\n",
       "<g id=\"edge13\" class=\"edge\"><title>inception1_conv5_relu_fwd&#45;&gt;inception1_conv5_fwd</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M383,-365.744C383,-357.204 383,-348.298 383,-340.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"383,-375.897 378.5,-365.897 383,-370.897 383,-365.897 383,-365.897 383,-365.897 383,-370.897 387.5,-365.897 383,-375.897 383,-375.897\"/>\n",
       "</g>\n",
       "<!-- inception1_concat0 -->\n",
       "<g id=\"node15\" class=\"node\"><title>inception1_concat0</title>\n",
       "<polygon fill=\"#fdb462\" stroke=\"black\" points=\"262,-528 168,-528 168,-470 262,-470 262,-528\"/>\n",
       "<text text-anchor=\"middle\" x=\"215\" y=\"-495.3\" font-family=\"Times,serif\" font-size=\"14.00\">inception1_concat0</text>\n",
       "</g>\n",
       "<!-- inception1_concat0&#45;&gt;inception1_conv0_relu_fwd -->\n",
       "<g id=\"edge14\" class=\"edge\"><title>inception1_concat0&#45;&gt;inception1_conv0_relu_fwd</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M158.587,-474.511C139.101,-464.287 118.334,-450.76 103,-434 78.1442,-406.832 62.6383,-366.727 54.409,-340.003\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"167.722,-479.119 156.767,-478.633 163.258,-476.867 158.794,-474.615 158.794,-474.615 158.794,-474.615 163.258,-476.867 160.821,-470.597 167.722,-479.119 167.722,-479.119\"/>\n",
       "</g>\n",
       "<!-- inception1_concat0&#45;&gt;inception1_conv2_relu_fwd -->\n",
       "<g id=\"edge15\" class=\"edge\"><title>inception1_concat0&#45;&gt;inception1_conv2_relu_fwd</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M192.569,-461.148C187.113,-452.186 181.363,-442.74 176.194,-434.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"197.894,-469.897 188.85,-463.695 195.294,-465.626 192.694,-461.355 192.694,-461.355 192.694,-461.355 195.294,-465.626 196.538,-459.015 197.894,-469.897 197.894,-469.897\"/>\n",
       "</g>\n",
       "<!-- inception1_concat0&#45;&gt;inception1_conv4_relu_fwd -->\n",
       "<g id=\"edge16\" class=\"edge\"><title>inception1_concat0&#45;&gt;inception1_conv4_relu_fwd</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M237.431,-461.148C242.887,-452.186 248.637,-442.74 253.806,-434.248\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"232.106,-469.897 233.462,-459.015 234.706,-465.626 237.306,-461.355 237.306,-461.355 237.306,-461.355 234.706,-465.626 241.15,-463.695 232.106,-469.897 232.106,-469.897\"/>\n",
       "</g>\n",
       "<!-- inception1_concat0&#45;&gt;inception1_conv5_relu_fwd -->\n",
       "<g id=\"edge17\" class=\"edge\"><title>inception1_concat0&#45;&gt;inception1_conv5_relu_fwd</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M271.067,-467.297C292.069,-455.795 315.701,-442.854 335.819,-431.837\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"262.244,-472.128 268.854,-463.378 266.63,-469.726 271.015,-467.325 271.015,-467.325 271.015,-467.325 266.63,-469.726 273.177,-471.272 262.244,-472.128 262.244,-472.128\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fced336c5c0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incp = Inception(64, 96, 128, 16, 32, 32)\n",
    "incp.initialize()\n",
    "incp.collect_params().reset_ctx(mx.cpu())\n",
    "incp.hybridize()\n",
    "x = nd.random.uniform(shape=(32,3,64,64))\n",
    "out = incp(x)\n",
    "sym = incp._cached_graph[1]\n",
    "mx.visualization.plot_network(sym, node_attrs={\"shape\": \"box\", \"fixedsize\": \"True\"})\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义Trainer和验证函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet import metric as mtc\n",
    "\n",
    "trainer = gluon.Trainer(finetune_net.collect_params(), 'sgd', {\n",
    "    'learning_rate': lr, 'momentum': momentum, 'wd': wd})\n",
    "\n",
    "\n",
    "def validate(net, val_data, ctx):\n",
    "    metric0 = mtc.Accuracy()\n",
    "    Loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "    val_loss0 = 0\n",
    "\n",
    "    for i, batch in enumerate(val_data):\n",
    "        data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        labels = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        outputs = [net(X) for X in data]\n",
    "        loss0 = [Loss(yhat, nd.array(y[:, 0], ctx=dvs)) for yhat, y, dvs in zip(outputs, labels, ctx)]\n",
    "        metric0.update([y[:, 0] for y in labels], [o for o in outputs])\n",
    "        val_loss0 += sum([l.mean().asscalar() for l in loss0]) / len(loss0)\n",
    "\n",
    "    _, val_acc0 = metric0.get()\n",
    "\n",
    "    return val_acc0, val_loss0 / len(val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Train: Acc: 0.922, loss: 0.205 | Val: Acc: 0.839, loss: 0.391 | time: 315.2\n",
      "[Epoch 1] Train: Acc: 0.957, loss: 0.116 | Val: Acc: 0.827, loss: 0.408 | time: 91.6\n"
     ]
    }
   ],
   "source": [
    "import time, math\n",
    "from mxnet import autograd as ag\n",
    "\n",
    "def progressbar(i, n, bar_len=40):\n",
    "    percents = math.ceil(100.0 * i / float(n))\n",
    "    filled_len = int(round(bar_len * i / float(n)))\n",
    "    prog_bar = '=' * filled_len + '-' * (bar_len - filled_len)\n",
    "    print('[%s] %s%s' % (prog_bar, percents, '%'), end='\\r')\n",
    "\n",
    "metric0 = mtc.Accuracy()\n",
    "Loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "lr_counter = 0\n",
    "num_batch = len(train_data)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    if epoch == lr_steps[lr_counter]:\n",
    "        trainer.set_learning_rate(trainer.learning_rate * lr_factor)\n",
    "        lr_counter += 1\n",
    "\n",
    "    tic = time.time()\n",
    "    train_loss = 0\n",
    "    metric0.reset()\n",
    "\n",
    "    for i, batch in enumerate(train_data):\n",
    "        data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        labels = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "\n",
    "        with ag.record():\n",
    "            outputs = [finetune_net(X) for X in data]\n",
    "            losses = [Loss(yhat, nd.array(y[:, 0], ctx=dvs))\n",
    "                      for yhat, y, dvs in zip(outputs, labels, ctx)]\n",
    "        for l in losses:\n",
    "            ag.backward(l)\n",
    "\n",
    "        trainer.step(batch_size)\n",
    "        train_loss += sum([l.mean().asscalar() for l in losses]) / len(losses)\n",
    "\n",
    "        metric0.update([y[:, 0] for y in labels], [o for o in outputs])\n",
    "\n",
    "        progressbar(i, num_batch - 1)\n",
    "\n",
    "    _, train_acc0 = metric0.get()\n",
    "    train_loss /= num_batch\n",
    "\n",
    "    val_acc0, val_loss0 = validate(finetune_net, val_data, ctx)\n",
    "\n",
    "    print('[Epoch %d] Train: Acc: %.3f, loss: %.3f |'\n",
    "        ' Val: Acc: %.3f, loss: %.3f | time: %.1f' %\n",
    "        (epoch, train_acc0, train_loss, val_acc0, val_loss0, time.time() - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 模型部署和C_API\n",
    "\n",
    "Mxnet序列化方法有几种:  \n",
    "- 训练时保存检查点`checkpoint`\n",
    "- 标准化输出`symbol.json`和`model-epoch.params`\n",
    "- ONNX模型`model.onnx`  \n",
    "\n",
    "这里以标准化输出为例, 这种模型保存后可以由c,c++等其他API加载调用,完成部署流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model-wiki-symbol.json', 'model-wiki-0002.params']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "finetune_net.export(path='./mxnetTL/models/model-wiki', epoch=2)\n",
    "os.listdir('./mxnetTL/models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单说明C_API的使用方法  \n",
    "```c++\n",
    "/*!\n",
    " * \\brief create a predictor\n",
    " * \\param symbol_json_str The JSON string of the symbol.\n",
    " * \\param param_bytes The in-memory raw bytes of parameter ndarray file.\n",
    " * \\param param_size The size of parameter ndarray file.\n",
    " * \\param dev_type The device type, 1: cpu, 2:gpu\n",
    " * \\param dev_id The device id of the predictor.\n",
    " * \\param num_input_nodes Number of input nodes to the net,\n",
    " *    For feedforward net, this is 1.\n",
    " * \\param input_keys The name of input argument.\n",
    " *    For feedforward net, this is {\"data\"}\n",
    " * \\param input_shape_indptr Index pointer of shapes of each input node.\n",
    " *    The length of this array = num_input_nodes + 1.\n",
    " *    For feedforward net that takes 4 dimensional input, this is {0, 4}.\n",
    " * \\param input_shape_data A flatted data of shapes of each input node.\n",
    " *    For feedforward net that takes 4 dimensional input, this is the shape data.\n",
    " * \\param out The created predictor handle.\n",
    " * \\return 0 when success, -1 when failure.\n",
    " */\n",
    "MXNET_DLL int MXPredCreate(const char* symbol_json_str,\n",
    "                           const void* param_bytes,\n",
    "                           int param_size,\n",
    "                           int dev_type, int dev_id,\n",
    "                           mx_uint num_input_nodes,\n",
    "                           const char** input_keys,\n",
    "                           const mx_uint* input_shape_indptr,\n",
    "                           const mx_uint* input_shape_data,\n",
    "                           PredictorHandle* out);\n",
    "                           \n",
    "/*!\n",
    " * \\brief Set the input data of predictor.\n",
    " * \\param handle The predictor handle.\n",
    " * \\param key The name of input node to set.\n",
    " *     For feedforward net, this is \"data\".\n",
    " * \\param data The pointer to the data to be set, with the shape specified in MXPredCreate.\n",
    " * \\param size The size of data array, used for safety check.\n",
    " * \\return 0 when success, -1 when failure.\n",
    " */\n",
    "MXNET_DLL int MXPredSetInput(PredictorHandle handle,\n",
    "                             const char* key,\n",
    "                             const mx_float* data,\n",
    "                             mx_uint size);\n",
    "\n",
    "/*!\n",
    " * \\brief Run a forward pass to get the output.\n",
    " * \\param handle The handle of the predictor.\n",
    " * \\return 0 when success, -1 when failure.\n",
    " */\n",
    "MXNET_DLL int MXPredForward(PredictorHandle handle);\n",
    "\n",
    "\n",
    "/*!\n",
    " * \\brief Get the output value of prediction.\n",
    " * \\param handle The handle of the predictor.\n",
    " * \\param index The index of output node, set to 0 if there is only one output.\n",
    " * \\param data User allocated data to hold the output.\n",
    " * \\param size The size of data array, used for safe checking.\n",
    " * \\return 0 when success, -1 when failure.\n",
    " */\n",
    "MXNET_DLL int MXPredGetOutput(PredictorHandle handle,\n",
    "                              mx_uint index,\n",
    "                              mx_float* data,\n",
    "                              mx_uint size);\n",
    "                           \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 一些有用的资源\n",
    "\n",
    "### 4.1 Gluon — 动手学深度学习教程\n",
    "这是一个深度学习的教学项目。MXnet的开发者使用 Apache MXNet (incubating) 的最新 gluon 接口来演示如何从0开始实现深度学习的各个算法。这份教程利用 Jupyter notebook 能将文档，代码，公式和图形统一在一起的优势，提供了一个交互式的学习体验。这个项目可以作为一本书，上课用的材料，现场演示的案例，和一个可以尽情拷贝的代码库。  \n",
    "这篇教程就是从这些资料中进行整理, 将其中比较常用的部分集中在这里.\n",
    "\n",
    "### 4.2 GluonCV — 计算机视觉的深度学习工具包\n",
    "基于用户假设，这个工具包提供如下的功能：\n",
    "\n",
    "1. 最近几年重要论文的复现\n",
    "1. 详细文档提供使用说明和代码讲解\n",
    "1. 提供预训练的模型可以直接使用\n",
    "1. 性能评测，方便大家在不同模型之间做取舍\n",
    "1. 每个模型实现和接口尽量保证一致性，降低使用新模型的学习门槛\n",
    "1. 定时做重新训练保证代码正确性\n",
    "1. 中文社区\n",
    "\n",
    "### 4.3 MXBoard — 助力 MXNet 数据可视化\n",
    "MXBoard 支持了 TensorBoard 中大部分的数据类型, 用直观的图标监视训练过程 :  \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/reminisce/mxboard-demo/master/pic/mnist_loss_train_valid_curves.png\" width = \"800\" align=left />   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 练习\n",
    "\n",
    "### 5.1 使用官方例程, 复现调参过程\n",
    "### 5.2 根据自己手中的数据集, 设计一个Dataset类, 辅助进行训练\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考资料\n",
    "1. MXnet-Gluon教程  [http://zh.gluon.ai](http://zh.gluon.ai)\n",
    "1. MXnet主页 [https://mxnet.incubator.apache.org](https://mxnet.incubator.apache.org)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
